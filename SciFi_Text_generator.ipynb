{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM3eZQlwRCbJeGAAzFV1qTr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AshwinUniyal/Text_Generation/blob/main/SciFi_Text_generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMm16cdKH2CL"
      },
      "source": [
        "# TASK 3 | Text generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Us-02LyHH1GT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dropout, Dense, Embedding, TimeDistributed, Activation\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sKgJKUCKH1ED",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be863167-0e8e-4799-eeb1-15b18993df6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "book = []\n",
        "with open('/content/drive/MyDrive/DL/internet_archive_scifi_v3.txt') as pdf:\n",
        "    for line in pdf:\n",
        "        book.append(line)\n",
        "book[0] = book[0][:len(book[0])//1000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8Kl3HbXKVOH",
        "outputId": "91d8d24a-1fd6-4f89-c42d-f64587422a78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "march  all stories new and complete publisher editor if is published bimonthly by quinn publishing company inc .  \n",
            "  kingston new york .  \n",
            "  volume  no .  \n",
            "   .  \n",
            "  copyright  by quinn publishing company inc .  \n",
            "  application for entry as second class matter at post office buffalo new york pending .  \n",
            "  subscription  for  issues in u .  \n",
            " s .  \n",
            "  and possessions canada  for  issues elsewhere  .  \n",
            "  aiiow four weeks for change of address .  \n",
            "  all stories appearing in this magazine are fiction .  \n",
            "  any similarity to actual persons is coincidental .  \n",
            "  c a fcopy .  \n",
            "  printed ia u .  \n",
            " s .  \n",
            "  a .  \n",
            "  a chat with the editor  i   science fiction magazine called if .  \n",
            "  the title was selected after much thought because of its brevity and on the theory it is indicative of the field and will be easy to remember .  \n",
            "  the tentative title that just morning and couldnt remember it until wed had a cup of coffee it was summarily discarded .  \n",
            "  a great deal of thought and effort lias gone into the formation of this magazine .  \n",
            "  we have had the aid of several very talented and generous people for which we are most grateful .  \n",
            "  much is due them for their warmhearted assistance .  \n",
            "  and now that the bulk of the formative work is done we will try to maintain if as one of the finest books on the market .  \n",
            "   t a great public demand for our magazine .  \n",
            "  in short why will you buy if .  \n",
            "  we cannot in honesty say we will publish at all times the best science fiction in the field .  \n",
            "  that would not be true .  \n",
            "  but we will have access to the best stories and we will get our fair share of works from the best writers .  \n",
            "  we definitely will not talk adult or juvenile relative to our content as we feel such terms are misleading .  \n",
            "  we would rather think at all times in the terms of story .  \n",
            "  some of the greatest escapist literature ever written treasure island for instance could be put into either category or both .  \n",
            "  and if edgar rice burroughs is juvenile then so a\n"
          ]
        }
      ],
      "source": [
        "import string\n",
        "punctuations = string.punctuation\n",
        "punctuations += '1234567890'\n",
        "eol = '.!?'\n",
        "\n",
        "cleaned_book = []\n",
        "for line in book:\n",
        "    cleaned_line = ''\n",
        "    for char in line:\n",
        "        if char in eol:\n",
        "            cleaned_line += ' . '\n",
        "            cleaned_line = cleaned_line.lower()\n",
        "            cleaned_book.append(cleaned_line)\n",
        "            cleaned_line = ''\n",
        "            continue\n",
        "        if char in punctuations or char == '\\n':\n",
        "            continue\n",
        "        cleaned_line += char\n",
        "    \n",
        "    #cleaned_book.append(cleaned_line)\n",
        "\n",
        "all_text = ' \\n '.join(cleaned_book)\n",
        "print(all_text[:2000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DKQs8ONQMmf",
        "outputId": "9abc1afe-68d3-4ae0-8a70-6546db622f06"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2429"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(cleaned_book)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CYHmMNPYWX8u"
      },
      "outputs": [],
      "source": [
        "## method 1\n",
        "\n",
        "# keras module for building LSTM \n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.models import Sequential\n",
        "import keras.utils as ku \n",
        "\n",
        "# set seeds for reproducability\n",
        "\n",
        "from numpy.random import seed\n",
        "\n",
        "seed(1)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string, os "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nbqRSgCVxUY",
        "outputId": "d26e0ad9-ca2e-4f34-f13d-4476b4157728"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['march  all stories new and complete publisher editor if is published bimonthly by quinn publishing company inc  ',\n",
              " ' kingston new york  ',\n",
              " ' volume  no  ',\n",
              " '   ',\n",
              " ' copyright  by quinn publishing company inc  ',\n",
              " ' application for entry as second class matter at post office buffalo new york pending  ',\n",
              " ' subscription  for  issues in u  ',\n",
              " 's  ',\n",
              " ' and possessions canada  for  issues elsewhere   ',\n",
              " ' aiiow four weeks for change of address  ']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "def clean_text(txt):\n",
        "    txt = \"\".join(v for v in txt if v not in string.punctuation).lower()\n",
        "    txt = txt.encode(\"utf8\").decode(\"ascii\",'ignore')\n",
        "    return txt \n",
        "\n",
        "corpus = [clean_text(x) for x in cleaned_book]\n",
        "corpus[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6-TnC16VxRz",
        "outputId": "ff11d8a0-4d67-46d4-bfca-b3455a22dd51"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1970, 41],\n",
              " [1970, 41, 421],\n",
              " [1970, 41, 421, 228],\n",
              " [1970, 41, 421, 228, 5],\n",
              " [1970, 41, 421, 228, 5, 771],\n",
              " [1970, 41, 421, 228, 5, 771, 1971],\n",
              " [1970, 41, 421, 228, 5, 771, 1971, 772],\n",
              " [1970, 41, 421, 228, 5, 771, 1971, 772, 57],\n",
              " [1970, 41, 421, 228, 5, 771, 1971, 772, 57, 37],\n",
              " [1970, 41, 421, 228, 5, 771, 1971, 772, 57, 37, 1972]]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "tokenizer = Tokenizer()\n",
        "\n",
        "def get_sequence_of_tokens(corpus):\n",
        "    ## tokenization\n",
        "    tokenizer.fit_on_texts(corpus)\n",
        "    total_words = len(tokenizer.word_index) + 1\n",
        "    \n",
        "    ## convert data to sequence of tokens \n",
        "    input_sequences = []\n",
        "    for line in corpus:\n",
        "        token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "        for i in range(1, len(token_list)):\n",
        "            n_gram_sequence = token_list[:i+1]\n",
        "            input_sequences.append(n_gram_sequence)\n",
        "    return input_sequences, total_words\n",
        "\n",
        "inp_sequences, total_words = get_sequence_of_tokens(corpus)\n",
        "inp_sequences[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uDx6g5xIVxPM"
      },
      "outputs": [],
      "source": [
        "def generate_padded_sequences(input_sequences):\n",
        "    max_sequence_len = max([len(x) for x in input_sequences])\n",
        "    input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "    \n",
        "    predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "    label = ku.to_categorical(label, num_classes=total_words)\n",
        "    return predictors, label, max_sequence_len\n",
        "\n",
        "predictors, label, max_sequence_len = generate_padded_sequences(inp_sequences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MpQT0PbVyVZ",
        "outputId": "f3340cdd-ac3d-4bc0-9c1f-85e13a00bd3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 83, 10)            47310     \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 100)               44400     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 100)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4731)              477831    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 569,541\n",
            "Trainable params: 569,541\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "def create_model(max_sequence_len, total_words):\n",
        "    input_len = max_sequence_len - 1\n",
        "    model = Sequential()\n",
        "    \n",
        "    # Add Input Embedding Layer\n",
        "    model.add(Embedding(total_words, 10, input_length=input_len))\n",
        "    \n",
        "    # Add Hidden Layer 1 - LSTM Layer\n",
        "    model.add(LSTM(100))\n",
        "    model.add(Dropout(0.1))\n",
        "    \n",
        "    # Add Output Layer\n",
        "    model.add(Dense(total_words, activation='softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "    \n",
        "    return model\n",
        "\n",
        "model = create_model(max_sequence_len, total_words)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BnNr7dieVySX"
      },
      "outputs": [],
      "source": [
        "model.fit(predictors, label, epochs=50, verbose=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "omfLhR79VyOz"
      },
      "outputs": [],
      "source": [
        "def generate_text(seed_text, next_words, model, max_sequence_len):\n",
        "    for _ in range(next_words):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "        #predicted = model.predict_classes(token_list, verbose=0)\n",
        "        predicted=model.predict(token_list, verbose=0) \n",
        "        classes=np.argmax(predicted,axis=1)\n",
        "        \n",
        "        output_word = \"\"\n",
        "        for word,index in tokenizer.word_index.items():\n",
        "            if index == classes:\n",
        "                output_word = word\n",
        "                break\n",
        "        seed_text += \" \"+output_word\n",
        "    return seed_text.title()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfvCsiP8VyL7",
        "outputId": "2d849cdd-aa43-471b-d0e8-7978c38a1863"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Night In Winter The City The Red Tape Of Unsnarled The Former Thing Was Wearily Out And The Number Of Light And Then It As The Job And It Was In Being To\n"
          ]
        }
      ],
      "source": [
        "print (generate_text(\"night in winter\", 30, model, max_sequence_len))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0NyQjPTKVMo",
        "outputId": "46f7724b-d21b-4de1-f3bb-39a81c1fcff3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1970, 41, 421, 228, 5, 771, 1971, 772, 57, 37, 1972, 1973, 43, 1277, 1278, 536, 1279], [1974, 228, 1280], [1975, 32], [], [1976, 43, 1277, 1278, 536, 1279], [1977, 16, 1978, 21, 643, 1979, 375, 19, 1980, 139, 1981, 228, 1280, 1982], [1983, 16, 1281, 9, 537], [148], [5, 1984, 1985, 16, 1281, 1986], [1987, 338, 1282, 16, 951, 4, 773]]\n"
          ]
        }
      ],
      "source": [
        "## method 2\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(cleaned_book)\n",
        "seq = tokenizer.texts_to_sequences(cleaned_book)\n",
        "print(seq[:10])\n",
        "# print(tokenizer.word_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHaQSYw4KVJt",
        "outputId": "c5dc0dae-b982-43d2-bea2-bb8e11e3d640"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corpus word length =  27034\n"
          ]
        }
      ],
      "source": [
        "corpus = [subitem for item in seq for subitem in item]\n",
        "print(\"corpus word length = \", len(corpus))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOlgNplrKVGJ",
        "outputId": "3e54c3c5-0b7a-41a5-b247-950af2ec1534"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "vocab size =  4730\n"
          ]
        }
      ],
      "source": [
        "vocab_size = len(tokenizer.word_index)\n",
        "print('vocab size = ', vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WsG9iztSKVDZ"
      },
      "outputs": [],
      "source": [
        "sentence_len = 20\n",
        "prediction_len = 1\n",
        "train_len = sentence_len - prediction_len\n",
        "\n",
        "train_seq = []\n",
        "for item in range(len(corpus) - sentence_len):\n",
        "    train_seq.append(corpus[item:item + sentence_len])\n",
        "    \n",
        "# free up corpus\n",
        "corpus = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4NSKJRk5LoUm"
      },
      "outputs": [],
      "source": [
        "trainX = []\n",
        "trainy = []\n",
        "for i in train_seq:\n",
        "    trainX.append(i[:train_len])\n",
        "    trainy.append(i[-1])\n",
        "\n",
        "# free up train sequence data\n",
        "train_seq = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-QC-hxrLoSn",
        "outputId": "63221a3a-9374-4e5a-daa4-6738c46522fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 19, 50)            236550    \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 128)               91648     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 4725)              609525    \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 4725)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 937,723\n",
            "Trainable params: 937,723\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "model = Sequential([\n",
        "    Embedding(vocab_size + 1, 50, input_length=train_len),\n",
        "    LSTM(128),\n",
        "    # Dense(150, activation='relu'),\n",
        "    Dense(4725),\n",
        "    Activation('softmax')\n",
        "])\n",
        "\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVar-zqWLoQp",
        "outputId": "2950fcbf-4b0f-4b9c-c8f4-6bec47169018"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "338/338 [==============================] - 14s 37ms/step - loss: 6.8936 - accuracy: 0.0529 - val_loss: 7.1564 - val_accuracy: 0.0639\n",
            "Epoch 2/25\n",
            "338/338 [==============================] - 4s 11ms/step - loss: 6.4501 - accuracy: 0.0556 - val_loss: 7.3709 - val_accuracy: 0.0713\n",
            "Epoch 3/25\n",
            "338/338 [==============================] - 2s 7ms/step - loss: 6.3443 - accuracy: 0.0640 - val_loss: 7.4801 - val_accuracy: 0.0716\n",
            "Epoch 4/25\n",
            "338/338 [==============================] - 3s 8ms/step - loss: 6.2205 - accuracy: 0.0692 - val_loss: 7.5285 - val_accuracy: 0.0724\n",
            "Epoch 5/25\n",
            "338/338 [==============================] - 2s 7ms/step - loss: 6.0887 - accuracy: 0.0759 - val_loss: 7.5704 - val_accuracy: 0.0731\n",
            "Epoch 6/25\n",
            "338/338 [==============================] - 2s 7ms/step - loss: 5.9578 - accuracy: 0.0824 - val_loss: 7.6342 - val_accuracy: 0.0779\n",
            "Epoch 7/25\n",
            "338/338 [==============================] - 3s 8ms/step - loss: 5.8206 - accuracy: 0.0910 - val_loss: 7.7160 - val_accuracy: 0.0788\n",
            "Epoch 8/25\n",
            "338/338 [==============================] - 2s 7ms/step - loss: 5.6742 - accuracy: 0.0965 - val_loss: 7.7663 - val_accuracy: 0.0775\n",
            "Epoch 9/25\n",
            "338/338 [==============================] - 2s 7ms/step - loss: 5.5292 - accuracy: 0.1037 - val_loss: 7.8324 - val_accuracy: 0.0811\n",
            "Epoch 10/25\n",
            "338/338 [==============================] - 2s 7ms/step - loss: 5.3866 - accuracy: 0.1123 - val_loss: 7.9144 - val_accuracy: 0.0779\n",
            "Epoch 11/25\n",
            "338/338 [==============================] - 2s 6ms/step - loss: 5.2448 - accuracy: 0.1199 - val_loss: 7.9813 - val_accuracy: 0.0783\n",
            "Epoch 12/25\n",
            "338/338 [==============================] - 2s 7ms/step - loss: 5.1064 - accuracy: 0.1270 - val_loss: 8.0914 - val_accuracy: 0.0779\n",
            "Epoch 13/25\n",
            "338/338 [==============================] - 2s 6ms/step - loss: 4.9691 - accuracy: 0.1345 - val_loss: 8.1721 - val_accuracy: 0.0781\n",
            "Epoch 14/25\n",
            "338/338 [==============================] - 3s 7ms/step - loss: 4.8368 - accuracy: 0.1402 - val_loss: 8.3407 - val_accuracy: 0.0757\n",
            "Epoch 15/25\n",
            "338/338 [==============================] - 2s 6ms/step - loss: 4.7070 - accuracy: 0.1474 - val_loss: 8.4123 - val_accuracy: 0.0798\n",
            "Epoch 16/25\n",
            "338/338 [==============================] - 2s 6ms/step - loss: 4.5766 - accuracy: 0.1545 - val_loss: 8.4894 - val_accuracy: 0.0757\n",
            "Epoch 17/25\n",
            "338/338 [==============================] - 2s 6ms/step - loss: 4.4451 - accuracy: 0.1664 - val_loss: 8.5857 - val_accuracy: 0.0787\n",
            "Epoch 18/25\n",
            "338/338 [==============================] - 2s 7ms/step - loss: 4.3154 - accuracy: 0.1761 - val_loss: 8.7076 - val_accuracy: 0.0783\n",
            "Epoch 19/25\n",
            "338/338 [==============================] - 2s 6ms/step - loss: 4.1855 - accuracy: 0.1913 - val_loss: 8.7563 - val_accuracy: 0.0735\n",
            "Epoch 20/25\n",
            "338/338 [==============================] - 2s 6ms/step - loss: 4.0557 - accuracy: 0.2073 - val_loss: 8.8848 - val_accuracy: 0.0750\n",
            "Epoch 21/25\n",
            "338/338 [==============================] - 2s 6ms/step - loss: 3.9268 - accuracy: 0.2262 - val_loss: 8.9749 - val_accuracy: 0.0727\n",
            "Epoch 22/25\n",
            "338/338 [==============================] - 2s 7ms/step - loss: 3.7969 - accuracy: 0.2487 - val_loss: 9.1038 - val_accuracy: 0.0701\n",
            "Epoch 23/25\n",
            "338/338 [==============================] - 2s 7ms/step - loss: 3.6746 - accuracy: 0.2688 - val_loss: 9.1752 - val_accuracy: 0.0683\n",
            "Epoch 24/25\n",
            "338/338 [==============================] - 2s 6ms/step - loss: 3.5499 - accuracy: 0.2874 - val_loss: 9.2568 - val_accuracy: 0.0655\n",
            "Epoch 25/25\n",
            "338/338 [==============================] - 2s 7ms/step - loss: 3.4286 - accuracy: 0.3094 - val_loss: 9.3707 - val_accuracy: 0.0648\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f780419dd90>"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.fit(np.asarray(trainX), pd.get_dummies(np.asarray(trainy)), batch_size=64, epochs=25, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YUNywywrLoOO"
      },
      "outputs": [],
      "source": [
        "INPUT_LENGTH = 19\n",
        "\n",
        "token_to_word_map = dict(map(reversed, tokenizer.word_index.items()))\n",
        "\n",
        "def generate_text(input_text, prediction_length):\n",
        "    tokens = tokenizer.texts_to_sequences([input_text])\n",
        "\n",
        "    while len(tokens[0]) < prediction_length:\n",
        "        if len(tokens[0]) <= INPUT_LENGTH:\n",
        "            padded_tokens = pad_sequences(tokens[-INPUT_LENGTH:], maxlen=INPUT_LENGTH)\n",
        "        else:\n",
        "            padded_tokens = [tokens[0][-INPUT_LENGTH:]]\n",
        "\n",
        "        prediction = model.predict(np.asarray(padded_tokens).reshape(1,-1))\n",
        "        tokens[0].append(prediction.argmax())\n",
        "        \n",
        "    tokens[0] = [134 if x==0 else x for x in tokens[0]]\n",
        "\n",
        "    generated_text = \" \".join(map(lambda x : token_to_word_map[x], tokens[0]))\n",
        "    generated_text = generated_text.replace(' .', '.')\n",
        "\n",
        "    return generated_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKDYZMBWLoLu",
        "outputId": "a45f7f5f-2a68-45d8-9445-8697c121ea5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 332ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 336ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "in jungle had he no lot her dont one then he you from on too his case he you from there he you laboratory he you no the two doing your day he you here you here you here it you no the theyll my take too it you here you here it you no the theyll my take too that you here you here you here it you no the theyll my take too it you here you here it you no the theyll my take too that you here you here you here it you no the theyll my take too it you here you here it you no the theyll my take too that you here you here you here it you no the theyll my take too it you here you here it you no the theyll my take too that you here you here you here it you no the theyll my take too it you here you here it you no the theyll my take too that you here you here you here it you no the theyll my take too it you here you here it you no the theyll my take too\n"
          ]
        }
      ],
      "source": [
        "print(generate_text(\"king in jungle\", 200))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  text model 3"
      ],
      "metadata": {
        "id": "TlQbJgn0QQpB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## create model\n",
        "\n",
        "\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import regularizers\n",
        "import tensorflow as tf\n",
        "\n"
      ],
      "metadata": {
        "id": "U9GaHm9UQQdF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 240, input_length=max_sequence_len-1))\n",
        "model.add(Bidirectional(LSTM(150, return_sequences = True)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(total_words/2, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "kiO45w7EQQKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fzf1by1S9bH",
        "outputId": "4aa7bc96-75d5-4ef1-8570-cc7131c4a4ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 83, 240)           1135440   \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 83, 300)          469200    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 83, 300)           0         \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 100)               160400    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 2365)              238865    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 4731)              11193546  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,197,451\n",
            "Trainable params: 13,197,451\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "\tdef on_epoch_end(self, epoch, logs={}):\n",
        "\t\tif(logs.get('accuracy')>0.93):\n",
        "\t\t\tprint(\"\\nReached 93% accuracy so cancelling training!\")\n",
        "\t\t\tself.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()\n",
        "\n",
        "history = model.fit(predictors, label, epochs=100, verbose=1, callbacks=[callbacks])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DupMx1GsQQDZ",
        "outputId": "220eb631-9880-4a53-908b-7b0309a93046"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "773/773 [==============================] - 82s 40ms/step - loss: 6.9144 - accuracy: 0.0537\n",
            "Epoch 2/100\n",
            "773/773 [==============================] - 16s 21ms/step - loss: 6.4974 - accuracy: 0.0556\n",
            "Epoch 3/100\n",
            "773/773 [==============================] - 16s 21ms/step - loss: 6.3216 - accuracy: 0.0584\n",
            "Epoch 4/100\n",
            "773/773 [==============================] - 16s 21ms/step - loss: 6.1947 - accuracy: 0.0657\n",
            "Epoch 5/100\n",
            "773/773 [==============================] - 15s 19ms/step - loss: 6.0725 - accuracy: 0.0775\n",
            "Epoch 6/100\n",
            "773/773 [==============================] - 15s 19ms/step - loss: 5.9471 - accuracy: 0.0862\n",
            "Epoch 7/100\n",
            "773/773 [==============================] - 15s 19ms/step - loss: 5.8364 - accuracy: 0.0952\n",
            "Epoch 8/100\n",
            "773/773 [==============================] - 15s 19ms/step - loss: 5.7436 - accuracy: 0.1018\n",
            "Epoch 9/100\n",
            "773/773 [==============================] - 15s 19ms/step - loss: 5.6546 - accuracy: 0.1069\n",
            "Epoch 10/100\n",
            "773/773 [==============================] - 15s 20ms/step - loss: 5.5724 - accuracy: 0.1127\n",
            "Epoch 11/100\n",
            "773/773 [==============================] - 15s 19ms/step - loss: 5.4778 - accuracy: 0.1181\n",
            "Epoch 12/100\n",
            "773/773 [==============================] - 15s 20ms/step - loss: 5.3924 - accuracy: 0.1236\n",
            "Epoch 13/100\n",
            "773/773 [==============================] - 15s 19ms/step - loss: 5.3085 - accuracy: 0.1300\n",
            "Epoch 14/100\n",
            "773/773 [==============================] - 15s 19ms/step - loss: 5.2200 - accuracy: 0.1352\n",
            "Epoch 15/100\n",
            "773/773 [==============================] - 15s 19ms/step - loss: 5.1501 - accuracy: 0.1417\n",
            "Epoch 16/100\n",
            "773/773 [==============================] - 15s 19ms/step - loss: 5.0604 - accuracy: 0.1491\n",
            "Epoch 17/100\n",
            "773/773 [==============================] - 14s 19ms/step - loss: 4.9782 - accuracy: 0.1538\n",
            "Epoch 18/100\n",
            "773/773 [==============================] - 14s 19ms/step - loss: 4.8961 - accuracy: 0.1596\n",
            "Epoch 19/100\n",
            "773/773 [==============================] - 14s 18ms/step - loss: 4.8068 - accuracy: 0.1671\n",
            "Epoch 20/100\n",
            "773/773 [==============================] - 14s 18ms/step - loss: 4.7253 - accuracy: 0.1731\n",
            "Epoch 21/100\n",
            "773/773 [==============================] - 14s 19ms/step - loss: 4.6443 - accuracy: 0.1806\n",
            "Epoch 22/100\n",
            "773/773 [==============================] - 14s 18ms/step - loss: 4.5554 - accuracy: 0.1872\n",
            "Epoch 23/100\n",
            "773/773 [==============================] - 14s 19ms/step - loss: 4.4737 - accuracy: 0.1962\n",
            "Epoch 24/100\n",
            "773/773 [==============================] - 14s 19ms/step - loss: 4.3939 - accuracy: 0.2036\n",
            "Epoch 25/100\n",
            "773/773 [==============================] - 14s 19ms/step - loss: 4.3146 - accuracy: 0.2111\n",
            "Epoch 26/100\n",
            "773/773 [==============================] - 15s 19ms/step - loss: 4.2375 - accuracy: 0.2205\n",
            "Epoch 27/100\n",
            "773/773 [==============================] - 14s 18ms/step - loss: 4.1578 - accuracy: 0.2294\n",
            "Epoch 28/100\n",
            "773/773 [==============================] - 14s 19ms/step - loss: 4.0826 - accuracy: 0.2392\n",
            "Epoch 29/100\n",
            "773/773 [==============================] - 14s 18ms/step - loss: 4.0102 - accuracy: 0.2461\n",
            "Epoch 30/100\n",
            "773/773 [==============================] - 14s 19ms/step - loss: 3.9354 - accuracy: 0.2560\n",
            "Epoch 31/100\n",
            "773/773 [==============================] - 14s 19ms/step - loss: 3.8662 - accuracy: 0.2666\n",
            "Epoch 32/100\n",
            "773/773 [==============================] - 14s 18ms/step - loss: 3.7977 - accuracy: 0.2765\n",
            "Epoch 33/100\n",
            "773/773 [==============================] - 14s 19ms/step - loss: 3.7300 - accuracy: 0.2837\n",
            "Epoch 34/100\n",
            "773/773 [==============================] - 14s 19ms/step - loss: 3.6689 - accuracy: 0.2959\n",
            "Epoch 35/100\n",
            "773/773 [==============================] - 14s 18ms/step - loss: 3.5883 - accuracy: 0.3069\n",
            "Epoch 36/100\n",
            "773/773 [==============================] - 14s 18ms/step - loss: 3.5275 - accuracy: 0.3173\n",
            "Epoch 37/100\n",
            "773/773 [==============================] - 14s 19ms/step - loss: 3.4728 - accuracy: 0.3274\n",
            "Epoch 38/100\n",
            "773/773 [==============================] - 14s 18ms/step - loss: 3.4170 - accuracy: 0.3360\n",
            "Epoch 39/100\n",
            "773/773 [==============================] - 14s 19ms/step - loss: 3.3551 - accuracy: 0.3484\n",
            "Epoch 40/100\n",
            "773/773 [==============================] - 15s 19ms/step - loss: 3.2912 - accuracy: 0.3589\n",
            "Epoch 41/100\n",
            "773/773 [==============================] - 14s 19ms/step - loss: 3.2391 - accuracy: 0.3718\n",
            "Epoch 42/100\n",
            "773/773 [==============================] - 14s 19ms/step - loss: 3.1782 - accuracy: 0.3813\n",
            "Epoch 43/100\n",
            "773/773 [==============================] - 15s 19ms/step - loss: 3.1270 - accuracy: 0.3894\n",
            "Epoch 44/100\n",
            "773/773 [==============================] - 14s 19ms/step - loss: 3.0706 - accuracy: 0.4049\n",
            "Epoch 45/100\n",
            "773/773 [==============================] - 15s 19ms/step - loss: 3.0167 - accuracy: 0.4124\n",
            "Epoch 46/100\n",
            "773/773 [==============================] - 14s 18ms/step - loss: 2.9728 - accuracy: 0.4254\n",
            "Epoch 47/100\n",
            "773/773 [==============================] - 14s 18ms/step - loss: 2.9199 - accuracy: 0.4328\n",
            "Epoch 48/100\n",
            "773/773 [==============================] - 15s 19ms/step - loss: 2.8792 - accuracy: 0.4398\n",
            "Epoch 49/100\n",
            "773/773 [==============================] - 15s 19ms/step - loss: 2.8263 - accuracy: 0.4522\n",
            "Epoch 50/100\n",
            "773/773 [==============================] - 14s 18ms/step - loss: 2.7834 - accuracy: 0.4616\n",
            "Epoch 51/100\n",
            "773/773 [==============================] - 14s 19ms/step - loss: 2.7336 - accuracy: 0.4683\n",
            "Epoch 52/100\n",
            "773/773 [==============================] - 15s 19ms/step - loss: 2.6963 - accuracy: 0.4796\n",
            "Epoch 53/100\n",
            "773/773 [==============================] - 14s 19ms/step - loss: 2.6553 - accuracy: 0.4885\n",
            "Epoch 54/100\n",
            "773/773 [==============================] - 14s 19ms/step - loss: 2.6144 - accuracy: 0.4943\n",
            "Epoch 55/100\n",
            "773/773 [==============================] - 15s 19ms/step - loss: 2.5603 - accuracy: 0.5071\n",
            "Epoch 56/100\n",
            "773/773 [==============================] - 14s 19ms/step - loss: 2.5318 - accuracy: 0.5113\n",
            "Epoch 57/100\n",
            "773/773 [==============================] - 14s 18ms/step - loss: 2.4900 - accuracy: 0.5224\n",
            "Epoch 58/100\n",
            "773/773 [==============================] - 15s 19ms/step - loss: 2.4519 - accuracy: 0.5324\n",
            "Epoch 59/100\n",
            "773/773 [==============================] - 15s 19ms/step - loss: 2.4152 - accuracy: 0.5372\n",
            "Epoch 60/100\n",
            "773/773 [==============================] - 15s 19ms/step - loss: 2.3816 - accuracy: 0.5449\n",
            "Epoch 61/100\n",
            "773/773 [==============================] - 15s 19ms/step - loss: 2.3458 - accuracy: 0.5527\n",
            "Epoch 62/100\n",
            "773/773 [==============================] - 14s 19ms/step - loss: 2.3101 - accuracy: 0.5583\n",
            "Epoch 63/100\n",
            "773/773 [==============================] - 15s 19ms/step - loss: 2.2902 - accuracy: 0.5651\n",
            "Epoch 64/100\n",
            "773/773 [==============================] - 15s 19ms/step - loss: 2.2568 - accuracy: 0.5687\n",
            "Epoch 65/100\n",
            "773/773 [==============================] - 14s 19ms/step - loss: 2.2179 - accuracy: 0.5769\n",
            "Epoch 66/100\n",
            "773/773 [==============================] - 15s 19ms/step - loss: 2.1804 - accuracy: 0.5864\n",
            "Epoch 67/100\n",
            "773/773 [==============================] - 15s 19ms/step - loss: 2.1618 - accuracy: 0.5888\n",
            "Epoch 68/100\n",
            "773/773 [==============================] - 14s 19ms/step - loss: 2.1348 - accuracy: 0.5962\n",
            "Epoch 69/100\n",
            "773/773 [==============================] - 14s 18ms/step - loss: 2.0912 - accuracy: 0.6065\n",
            "Epoch 70/100\n",
            "773/773 [==============================] - 14s 18ms/step - loss: 2.0841 - accuracy: 0.6045\n",
            "Epoch 71/100\n",
            "773/773 [==============================] - 14s 18ms/step - loss: 2.0421 - accuracy: 0.6141\n",
            "Epoch 72/100\n",
            "773/773 [==============================] - 14s 19ms/step - loss: 2.0192 - accuracy: 0.6177\n",
            "Epoch 73/100\n",
            "773/773 [==============================] - 14s 18ms/step - loss: 2.0043 - accuracy: 0.6219\n",
            "Epoch 74/100\n",
            "773/773 [==============================] - 14s 18ms/step - loss: 1.9708 - accuracy: 0.6299\n",
            "Epoch 75/100\n",
            "773/773 [==============================] - 14s 18ms/step - loss: 1.9385 - accuracy: 0.6370\n",
            "Epoch 76/100\n",
            "773/773 [==============================] - 15s 19ms/step - loss: 1.9154 - accuracy: 0.6396\n",
            "Epoch 77/100\n",
            "773/773 [==============================] - 14s 19ms/step - loss: 1.8932 - accuracy: 0.6444\n",
            "Epoch 78/100\n",
            "773/773 [==============================] - 15s 19ms/step - loss: 1.8906 - accuracy: 0.6436\n",
            "Epoch 79/100\n",
            "773/773 [==============================] - 15s 19ms/step - loss: 1.8658 - accuracy: 0.6492\n",
            "Epoch 80/100\n",
            "773/773 [==============================] - 14s 18ms/step - loss: 1.8349 - accuracy: 0.6555\n",
            "Epoch 81/100\n",
            "773/773 [==============================] - 14s 18ms/step - loss: 1.8045 - accuracy: 0.6632\n",
            "Epoch 82/100\n",
            "773/773 [==============================] - 14s 19ms/step - loss: 1.7778 - accuracy: 0.6691\n",
            "Epoch 83/100\n",
            "773/773 [==============================] - 15s 19ms/step - loss: 1.7664 - accuracy: 0.6725\n",
            "Epoch 84/100\n",
            "773/773 [==============================] - 14s 18ms/step - loss: 1.7505 - accuracy: 0.6754\n",
            "Epoch 85/100\n",
            "773/773 [==============================] - 14s 19ms/step - loss: 1.7315 - accuracy: 0.6770\n",
            "Epoch 86/100\n",
            "773/773 [==============================] - 14s 18ms/step - loss: 1.7201 - accuracy: 0.6803\n",
            "Epoch 87/100\n",
            "773/773 [==============================] - 14s 18ms/step - loss: 1.7003 - accuracy: 0.6844\n",
            "Epoch 88/100\n",
            "773/773 [==============================] - 14s 18ms/step - loss: 1.6728 - accuracy: 0.6882\n",
            "Epoch 89/100\n",
            "773/773 [==============================] - 14s 19ms/step - loss: 1.6592 - accuracy: 0.6919\n",
            "Epoch 90/100\n",
            "773/773 [==============================] - 14s 18ms/step - loss: 1.6417 - accuracy: 0.6944\n",
            "Epoch 91/100\n",
            "773/773 [==============================] - 14s 18ms/step - loss: 1.6324 - accuracy: 0.6973\n",
            "Epoch 92/100\n",
            "773/773 [==============================] - 14s 18ms/step - loss: 1.6242 - accuracy: 0.6967\n",
            "Epoch 93/100\n",
            "773/773 [==============================] - 14s 18ms/step - loss: 1.5897 - accuracy: 0.7075\n",
            "Epoch 94/100\n",
            "773/773 [==============================] - 14s 19ms/step - loss: 1.5760 - accuracy: 0.7095\n",
            "Epoch 95/100\n",
            "773/773 [==============================] - 15s 19ms/step - loss: 1.5621 - accuracy: 0.7105\n",
            "Epoch 96/100\n",
            "773/773 [==============================] - 15s 19ms/step - loss: 1.5431 - accuracy: 0.7165\n",
            "Epoch 97/100\n",
            "773/773 [==============================] - 15s 19ms/step - loss: 1.5277 - accuracy: 0.7174\n",
            "Epoch 98/100\n",
            "773/773 [==============================] - 15s 19ms/step - loss: 1.5103 - accuracy: 0.7233\n",
            "Epoch 99/100\n",
            "773/773 [==============================] - 14s 18ms/step - loss: 1.5140 - accuracy: 0.7204\n",
            "Epoch 100/100\n",
            "773/773 [==============================] - 14s 18ms/step - loss: 1.4874 - accuracy: 0.7264\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(seed_text, next_words, model, max_sequence_len):\n",
        "    for _ in range(next_words):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "        #predicted = model.predict_classes(token_list, verbose=0)\n",
        "        predicted=model.predict(token_list, verbose=0) \n",
        "        classes=np.argmax(predicted,axis=1)\n",
        "        \n",
        "        output_word = \"\"\n",
        "        for word,index in tokenizer.word_index.items():\n",
        "            if index == classes:\n",
        "                output_word = word\n",
        "                break\n",
        "        seed_text += \" \"+output_word\n",
        "    return seed_text.title()"
      ],
      "metadata": {
        "id": "aa2XL0FpQPSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (generate_text(\"boy in the jungle\", 30, model, max_sequence_len))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgPOK3rPZZeM",
        "outputId": "bc478c2d-ce39-499e-b977-2be2258c0ccc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Boy In The Jungle Niek Parcels His Own Troubles To Hear Him New And Committed A Grievous Faux Pas He Grunted Hated Him With A Fairly Light Sentence Maybe Even An Eightfoot Refrigerator Glancing\n"
          ]
        }
      ]
    }
  ]
}